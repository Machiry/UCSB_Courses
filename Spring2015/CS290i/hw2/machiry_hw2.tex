\documentclass[11pt, pdftex]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{semantic}
\usepackage[hyphens]{url}
\usepackage[breaklinks]{hyperref}
\usepackage[demo]{graphicx}
\usepackage{subcaption}
\usepackage{hyperref}
\title{Assignment (MiniProject) #2}
\author{Machiry Aravind Kumar}
\date{UCSB}
\begin{document}
\maketitle
\section{Dataset}
\subsection{Seeds Data Set}
This dataset is from UCI Archive: \url{https://archive.ics.uci.edu/ml/datasets/seeds}. Dataset contains various Geometric parameters of wheat kernels measured using a soft X-ray technique. It is non-destructive and considerably cheaper than other more sophisticated imaging techniques like scanning microscopy or laser technology. The problem is to classify these into one of the 3 different classes viz  Kama, Rosa and Canadian. For this Assignment, I selected samples for only 2 classes: Kama (Class label: 1) and Rosa (Class label: 2). Available Features in the dataset are:
\begin{itemize}
\item area A.
\item perimeter P.
\item compactness C.
\item length of kernel.
\item width of kernel,
\item asymmetry coefficient
\item length of kernel groove.
\end{itemize}
To use LDA, I selected 2 features viz $\textbf{area}$ and $\textbf{perimeter}$. Distribution of the corresponding features is as shown in figure: \ref{fig:seeds}.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{pics/FeaturesVisualization.png} 
    \caption{Dataset Features Visualization}
    \label{fig:seeds}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{pics/decbou.png} 
    \caption{Dataset Features with Decision Line}
    \label{fig:decbou}
\end{figure}

\section{Running LDA classifier on the Dataset}
I ran LDA function from sklearn.ida module with default arguments as shown below:

\begin{lstlisting}
classifier = LDA()
classifier.fit(features, classes)

weights = classifier.coef_[0]
dec_s = weights[0] / weights[1]
x = np.linspace(10, 22)

Line Equation:
y = dec_s * x - (classifier.intercept_[0] / weights[1])
\end{lstlisting}

It provided weights and intercept using which I was able to get line equation of the decision boundary. The resulting line equation for Decision boundary is: $\textbf{y = -0.011*x - 15.02}$. Figure \ref{fig:decbou} shows the features with decision line.


\section{Classification Accuracy}
The results for different values of n are as shown in Table \ref{tab:seeds}. The results are pretty accurate with 91$\%$ Accuracy and doesn't vary much with n, which proves that features are good for the classification. It also proves that a linear classifier is good fit for this classification problem.
\begin{table}
\centering
\begin{tabular}{ | c | c | c |}
    \hline
    {\bf N} & {\bf Mean Accuracy} & {\bf Mean Error}\\ 
    \hline
    3 & 91.3 & 8.63\\
	\hline
	4 & 91.99 & 8.00\\
	\hline
	5 & 91.42 & 8.57\\
	\hline
	6 & 91.16 & 8.83\\
	\hline
	7 & 91.42 & 8.57\\
	\hline
	8 & 90.97 & 9.02\\
	\hline
	9 & 90.97 & 9.02\\
	\hline
	10 & 91.42 & 8.57\\
	\hline
	\end{tabular}
	\caption{Cross Validation Results for Seeds Dataset using LDA}
    \label{tab:seeds}
\end{table}
\end{document}